{
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import os\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger('__main__')\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "class GoogleDriveManager:\n",
        "    \"\"\"\n",
        "    Manages Google Drive operations including listing, filtering, downloading, and uploading files.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, folder_id):\n",
        "        \"\"\"\n",
        "        Initialize the GoogleDriveManager with authentication and folder ID.\n",
        "\n",
        "        Args:\n",
        "            folder_id: The Google Drive folder ID to work with\n",
        "        \"\"\"\n",
        "        self.folder_id = folder_id\n",
        "        self.drive_service = None\n",
        "        self.files_df = None  # Cache for file listings\n",
        "\n",
        "        # Authenticate and build service\n",
        "        self._authenticate()\n",
        "\n",
        "    def _authenticate(self):\n",
        "        \"\"\"Authenticate with Google Drive and build the service object.\"\"\"\n",
        "        try:\n",
        "            auth.authenticate_user()\n",
        "            self.drive_service = build('drive', 'v3')\n",
        "            logger.info(\"✅ Successfully authenticated with Google Drive\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Authentication failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def list_all_files(self, force_refresh=False):\n",
        "        \"\"\"\n",
        "        Recursively list all files in the folder and subfolders.\n",
        "\n",
        "        Args:\n",
        "            force_refresh: If True, force a new listing even if cached data exists\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with columns [file_name, file_path, file_id, file_url]\n",
        "        \"\"\"\n",
        "        if self.files_df is not None and not force_refresh:\n",
        "            logger.info(\"📋 Using cached file list\")\n",
        "            return self.files_df\n",
        "\n",
        "        logger.info(\"🔍 Listing all files in folder...\")\n",
        "        all_files = self._list_files_recursive(self.folder_id)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        if all_files:\n",
        "            self.files_df = pd.DataFrame(all_files)\n",
        "\n",
        "            # Deduplicate by folder+name (file_path already encodes folder)\n",
        "            self.files_df = self.files_df.drop_duplicates(\n",
        "                subset=[\"file_path\", \"file_name\"], keep=\"first\"\n",
        "            )\n",
        "\n",
        "            logger.info(f\"✅ Found {len(self.files_df)} unique files\")\n",
        "        else:\n",
        "            self.files_df = pd.DataFrame(columns=['file_name', 'file_path', 'file_id', 'file_url'])\n",
        "            logger.info(\"📁 No files found in folder\")\n",
        "\n",
        "        return self.files_df\n",
        "\n",
        "    def _list_files_recursive(self, parent_id, parent_path=\"\"):\n",
        "        \"\"\"\n",
        "        Recursively list files in a folder.\n",
        "\n",
        "        Args:\n",
        "            parent_id: Google Drive folder ID\n",
        "            parent_path: Path string for tracking folder hierarchy\n",
        "\n",
        "        Returns:\n",
        "            list: List of file dictionaries\n",
        "        \"\"\"\n",
        "        all_files = []\n",
        "        query = f\"'{parent_id}' in parents and trashed=false\"\n",
        "        page_token = None\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                response = self.drive_service.files().list(\n",
        "                    q=query,\n",
        "                    spaces='drive',\n",
        "                    fields='nextPageToken, files(id, name, mimeType)',\n",
        "                    pageToken=page_token\n",
        "                ).execute()\n",
        "\n",
        "                for item in response.get('files', []):\n",
        "                    item_path = f\"{parent_path}/{item['name']}\" if parent_path else item['name']\n",
        "\n",
        "                    if item['mimeType'] == 'application/vnd.google-apps.folder':\n",
        "                        # Recurse into subfolder\n",
        "                        all_files.extend(self._list_files_recursive(item['id'], item_path))\n",
        "                    else:\n",
        "                        all_files.append({\n",
        "                            \"file_name\": item['name'],\n",
        "                            \"file_path\": item_path,\n",
        "                            \"file_id\": item['id'],\n",
        "                            \"file_url\": f\"https://drive.google.com/file/d/{item['id']}/view?usp=sharing\"\n",
        "                        })\n",
        "\n",
        "                page_token = response.get('nextPageToken', None)\n",
        "                if page_token is None:\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"❌ Error listing files in {parent_path}: {e}\")\n",
        "                break\n",
        "\n",
        "        return all_files\n",
        "\n",
        "    def filter_files(self, df=None, years=None, chapters=None):\n",
        "        \"\"\"\n",
        "        Filter files based on specified years and chapters using exact matching.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to filter (if None, uses cached files_df)\n",
        "            years: List of years to include (e.g., [2021, 2022, 2023])\n",
        "            chapters: List of chapter numbers to include (e.g., [1, 2, 5, 10])\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Filtered DataFrame containing only requested files\n",
        "        \"\"\"\n",
        "        # Use provided df or cached one\n",
        "        if df is None:\n",
        "            if self.files_df is None:\n",
        "                logger.warning(\"⚠️ No files listed yet. Running list_all_files() first.\")\n",
        "                self.list_all_files()\n",
        "            df = self.files_df.copy()\n",
        "        else:\n",
        "            df = df.copy()\n",
        "\n",
        "        if df.empty:\n",
        "            logger.warning(\"⚠️ No files to filter\")\n",
        "            return df\n",
        "\n",
        "        # Apply year filter\n",
        "        if years is not None:\n",
        "            year_strings = [str(year) for year in years]\n",
        "            # Exact match: year must be a folder in the path\n",
        "            year_mask = df['file_path'].apply(\n",
        "                lambda path: any(f\"/{year}/\" in f\"/{path}\" or path.startswith(f\"{year}/\")\n",
        "                               for year in year_strings)\n",
        "            )\n",
        "            df = df[year_mask]\n",
        "            logger.info(f\"📅 Filtered for years: {years} - {len(df)} files\")\n",
        "\n",
        "        # Apply chapter filter\n",
        "        if chapters is not None:\n",
        "            # Exact match for filename pattern: 01.docx, 02.docx, etc.\n",
        "            chapter_filenames = [f\"{ch:02d}.docx\" for ch in chapters]\n",
        "            chapter_mask = df['file_name'].apply(\n",
        "                lambda name: name in chapter_filenames\n",
        "            )\n",
        "            df = df[chapter_mask]\n",
        "            logger.info(f\"📖 Filtered for chapters: {chapters} - {len(df)} files\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def download_files(self, filtered_df, download_dir=\"/content/reports\"):\n",
        "        \"\"\"\n",
        "        Download files from a filtered DataFrame.\n",
        "\n",
        "        Args:\n",
        "            filtered_df: DataFrame containing files to download\n",
        "            download_dir: Base directory for downloads\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary mapping file paths to local paths\n",
        "        \"\"\"\n",
        "        if filtered_df is None or filtered_df.empty:\n",
        "            logger.warning(\"⚠️ No files to download\")\n",
        "            return {}\n",
        "\n",
        "        downloaded_files = {}\n",
        "        total_files = len(filtered_df)\n",
        "\n",
        "        logger.info(f\"📥 Starting download of {total_files} files...\")\n",
        "\n",
        "        for idx, row in filtered_df.iterrows():\n",
        "            file_id = row['file_id']\n",
        "            file_name = row['file_name']\n",
        "            file_path = row['file_path']\n",
        "\n",
        "            # Extract year from path (assuming structure: year/filename)\n",
        "            path_parts = file_path.split('/')\n",
        "            if len(path_parts) >= 2:\n",
        "                year = path_parts[0]\n",
        "                local_path = os.path.join(download_dir, year, file_name)\n",
        "            else:\n",
        "                local_path = os.path.join(download_dir, file_name)\n",
        "\n",
        "            # Ensure directory exists\n",
        "            os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
        "\n",
        "            try:\n",
        "                # Download file\n",
        "                request = self.drive_service.files().get_media(fileId=file_id)\n",
        "                fh = io.FileIO(local_path, \"wb\")\n",
        "                downloader = MediaIoBaseDownload(fh, request)\n",
        "\n",
        "                done = False\n",
        "                while not done:\n",
        "                    status, done = downloader.next_chunk()\n",
        "                    if status:\n",
        "                        progress = int(status.progress() * 100)\n",
        "                        print(f\"⬇️  Downloading {file_name}: {progress}%\", end='\\r')\n",
        "\n",
        "                logger.info(f\"✅ Downloaded {file_name} to {local_path}\")\n",
        "                downloaded_files[file_path] = local_path\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ Failed to download {file_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        logger.info(f\"✅ Download complete: {len(downloaded_files)}/{total_files} files\")\n",
        "        return downloaded_files\n",
        "\n",
        "    def download_selective(self, years=None, chapters=None, download_dir=\"/content/reports\"):\n",
        "        \"\"\"\n",
        "        Convenience method to list, filter, and download files in one operation.\n",
        "\n",
        "        Args:\n",
        "            years: List of years to download (e.g., [2021, 2022, 2023])\n",
        "            chapters: List of chapter numbers to download (e.g., [1, 2, 5, 10])\n",
        "            download_dir: Base directory for downloads\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary mapping file paths to local paths\n",
        "\n",
        "        Example:\n",
        "            # Download chapters 1-5 for years 2021-2023\n",
        "            manager.download_selective(\n",
        "                years=range(2021, 2024),\n",
        "                chapters=range(1, 6),\n",
        "                download_dir=\"/content/reports\"\n",
        "            )\n",
        "        \"\"\"\n",
        "        # Step 1: List all files\n",
        "        logger.info(\"🚀 Starting selective download workflow...\")\n",
        "        all_files = self.list_all_files()\n",
        "\n",
        "        # Step 2: Filter files\n",
        "        filtered_files = self.filter_files(all_files, years=years, chapters=chapters)\n",
        "\n",
        "        if filtered_files is None or filtered_files.empty:\n",
        "            logger.warning(\"⚠️ No files match the specified criteria\")\n",
        "            return {}\n",
        "\n",
        "        logger.info(f\"📊 Found {len(filtered_files)} files matching criteria\")\n",
        "\n",
        "        # Step 3: Download filtered files\n",
        "        downloaded = self.download_files(filtered_files, download_dir)\n",
        "\n",
        "        return downloaded\n",
        "\n",
        "    def get_summary(self, df=None):\n",
        "        \"\"\"\n",
        "        Get summary statistics about the files.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to summarize (if None, uses cached files_df)\n",
        "\n",
        "        Returns:\n",
        "            dict: Summary statistics\n",
        "        \"\"\"\n",
        "        if df is None:\n",
        "            if self.files_df is None:\n",
        "                logger.warning(\"⚠️ No files listed yet. Running list_all_files() first.\")\n",
        "                self.list_all_files()\n",
        "            df = self.files_df\n",
        "\n",
        "        if df is None or df.empty:\n",
        "            return {\"total_files\": 0, \"years\": [], \"chapters\": []}\n",
        "\n",
        "        # Extract years from paths\n",
        "        years = df['file_path'].apply(lambda x: x.split('/')[0] if '/' in x else None)\n",
        "        years = sorted(years.dropna().unique())\n",
        "\n",
        "        # Extract chapters from filenames (assuming pattern: 01.docx, 02.docx)\n",
        "        chapters = df['file_name'].apply(\n",
        "            lambda x: int(x[:2]) if x[:2].isdigit() and x.endswith('.docx') else None\n",
        "        )\n",
        "        chapters = sorted(chapters.dropna().unique())\n",
        "\n",
        "        summary = {\n",
        "            \"total_files\": len(df),\n",
        "            \"years\": years,\n",
        "            \"year_count\": len(years),\n",
        "            \"chapters\": chapters,\n",
        "            \"chapter_count\": len(chapters),\n",
        "            \"file_types\": df['file_name'].apply(lambda x: x.split('.')[-1]).value_counts().to_dict()\n",
        "        }\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def preview_files(self, df=None, n=10):\n",
        "        \"\"\"\n",
        "        Preview first n files from the DataFrame.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to preview (if None, uses cached files_df)\n",
        "            n: Number of files to preview\n",
        "        \"\"\"\n",
        "        if df is None:\n",
        "            if self.files_df is None:\n",
        "                logger.warning(\"⚠️ No files listed yet. Running list_all_files() first.\")\n",
        "                self.list_all_files()\n",
        "            df = self.files_df\n",
        "\n",
        "        if df is None or df.empty:\n",
        "            logger.info(\"No files to preview\")\n",
        "            return\n",
        "\n",
        "        preview = df.head(n)[['file_name', 'file_path']]\n",
        "        logger.info(f\"\\n📋 Preview of first {min(n, len(df))} files:\")\n",
        "        for idx, row in preview.iterrows():\n",
        "            logger.info(f\"  {row['file_path']}\")\n",
        "\n",
        "    def check_missing_files(self, years, chapters):\n",
        "        \"\"\"\n",
        "        Check which year/chapter combinations are missing.\n",
        "\n",
        "        Args:\n",
        "            years: List of years to check\n",
        "            chapters: List of chapter numbers to check\n",
        "\n",
        "        Returns:\n",
        "            list: List of missing (year, chapter) tuples\n",
        "        \"\"\"\n",
        "        if self.files_df is None:\n",
        "            self.list_all_files()\n",
        "\n",
        "        missing = []\n",
        "\n",
        "        for year in years:\n",
        "            for chapter in chapters:\n",
        "                # Check if this combination exists\n",
        "                filtered = self.filter_files(\n",
        "                    self.files_df,\n",
        "                    years=[year],\n",
        "                    chapters=[chapter]\n",
        "                )\n",
        "\n",
        "                if filtered is None or filtered.empty:\n",
        "                    missing.append((year, chapter))\n",
        "                    logger.warning(f\"⚠️ Missing: Year {year}, Chapter {chapter:02d}\")\n",
        "\n",
        "        if missing:\n",
        "            logger.info(f\"📊 Total missing files: {len(missing)}\")\n",
        "        else:\n",
        "            logger.info(\"✅ All requested files are present\")\n",
        "\n",
        "        return missing"
      ],
      "metadata": {
        "id": "Km-JPMKWmgBM"
      },
      "execution_count": 2,
      "outputs": []
    }
