{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzAE1ASwSFBuzHx7ysXikv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiragelb/NCC-Statistical-Reports/blob/main/File_conversion_and_upload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FRYC16Ps4Mn"
      },
      "outputs": [],
      "source": [
        "!apt-get install pandoc\n",
        "!pip install pypandoc\n",
        "!pip install python-docx\n",
        "!pip install docx2txt\n",
        "!apt-get install -y libreoffice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting folders id from shared memory\n",
        "\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# Authenticate\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "folder_id = \"1e0eA-AIsz_BSwVHOppJMXECX42hBfG4J\"\n",
        "\n",
        "def list_all_files_in_folder_recursive(parent_id, parent_path=\"\"):\n",
        "    \"\"\"Recursively list all files in a folder and subfolders\"\"\"\n",
        "    all_files = []\n",
        "\n",
        "    query = f\"'{parent_id}' in parents and trashed=false\"\n",
        "    page_token = None\n",
        "\n",
        "    while True:\n",
        "        response = drive_service.files().list(\n",
        "            q=query,\n",
        "            spaces='drive',\n",
        "            fields='nextPageToken, files(id, name, mimeType)',\n",
        "            pageToken=page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response.get('files', []):\n",
        "            item_path = f\"{parent_path}/{item['name']}\" if parent_path else item['name']\n",
        "\n",
        "            if item['mimeType'] == 'application/vnd.google-apps.folder':\n",
        "                # Recurse into subfolder\n",
        "                all_files.extend(list_all_files_in_folder_recursive(item['id'], item_path))\n",
        "            else:\n",
        "                all_files.append({\n",
        "                    \"file_name\": item['name'],\n",
        "                    \"file_path\": item_path,\n",
        "                    \"file_id\": item['id'],\n",
        "                    \"file_url\": f\"https://drive.google.com/file/d/{item['id']}/view?usp=sharing\"\n",
        "                })\n",
        "\n",
        "        page_token = response.get('nextPageToken', None)\n",
        "        if page_token is None:\n",
        "            break\n",
        "\n",
        "    return all_files\n",
        "\n",
        "# Run the recursive function\n",
        "files_list = list_all_files_in_folder_recursive(folder_id)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_files = pd.DataFrame(files_list)\n",
        "##df_files.head()\n",
        "\n",
        "##getting local id of the file\n",
        "!pip install python-docx\n",
        "import os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import io\n",
        "\n",
        "def get_chapter_file(chapter_num: int, year: str, download_dir=\"/content\") -> str:\n",
        "    \"\"\"\n",
        "    Download a chapter file for a given year from Google Drive and return its local path.\n",
        "\n",
        "    Args:\n",
        "        chapter_num (int): The chapter number (e.g., 1, 2, ..., 14).\n",
        "        year (str): The year folder name.\n",
        "        download_dir (str): Local folder to save the file. Defaults to /content in Colab.\n",
        "\n",
        "    Returns:\n",
        "        str: Local path to the downloaded file, or None if not found.\n",
        "    \"\"\"\n",
        "    # Normalize chapter filename (01, 02, ...)\n",
        "    chapter_str = f\"{chapter_num:02}\"\n",
        "\n",
        "    # Find matching file in df_files\n",
        "    match = df_files[\n",
        "        (df_files[\"file_name\"].str.contains(chapter_str)) &\n",
        "        (df_files[\"file_path\"].str.contains(f\"{year}/\"))\n",
        "    ]\n",
        "\n",
        "    if match.empty:\n",
        "        print(f\"‚ùå No file found for chapter {chapter_str} in year {year}\")\n",
        "        return None\n",
        "\n",
        "    file_id = match.iloc[0][\"file_id\"]\n",
        "    file_name = match.iloc[0][\"file_name\"]\n",
        "    local_path = os.path.join(download_dir, year, file_name)\n",
        "\n",
        "    # Ensure year directory exists locally\n",
        "    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
        "\n",
        "    # Download the file from Google Drive\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    fh = io.FileIO(local_path, \"wb\")\n",
        "    downloader = MediaIoBaseDownload(fh, request)\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        status, done = downloader.next_chunk()\n",
        "        if status:\n",
        "            print(f\"‚¨áÔ∏è Download {int(status.progress() * 100)}%.\")\n",
        "\n",
        "    print(f\"‚úÖ Saved to {local_path}\")\n",
        "    return local_path\n",
        "\n",
        "from docx import Document\n",
        "\n",
        "# After downloading the file\n",
        "# sanity check\n",
        "path = get_chapter_file(14, \"2015\")\n",
        "print(\"Local file:\", path)\n",
        "\n",
        "if path and path.endswith(\".docx\"):\n",
        "    doc = Document(path)\n",
        "    full_text = \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip() != \"\"])\n",
        "\n",
        "    # Split into sentences (naive split by period/full stop)\n",
        "    sentences = full_text.replace(\"\\n\", \" \").split(\".\")\n",
        "\n",
        "    # Print first few sentences\n",
        "    preview_count = 3\n",
        "    preview_sentences = [s.strip() for s in sentences if s.strip()][:preview_count]\n",
        "    print(\"\\nPreview of content:\")\n",
        "    for i, s in enumerate(preview_sentences, 1):\n",
        "        print(f\"{i}. {s}.\")\n",
        "\n",
        "\n",
        "\n",
        "    #a code that downloads the files to a directory called content/reports\n",
        "import os\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "def download_all_chapters(download_dir=\"/content/reports\", years=range(2001, 2025), chapters=range(1, 16)):\n",
        "    \"\"\"\n",
        "    Downloads all chapters for all years to local environment.\n",
        "\n",
        "    Returns:\n",
        "        dict: {year: {chapter_number: local_path}}\n",
        "    \"\"\"\n",
        "    all_paths = {}\n",
        "\n",
        "    for year in years:\n",
        "        year_str = str(year)\n",
        "        all_paths[year_str] = {}\n",
        "\n",
        "        for chapter in chapters:\n",
        "            chapter_str = f\"{chapter:02}\"\n",
        "\n",
        "            # Find matching file in df_files\n",
        "            match = df_files[\n",
        "                (df_files[\"file_name\"].str.contains(chapter_str)) &\n",
        "                (df_files[\"file_path\"].str.contains(f\"{year_str}/\"))\n",
        "            ]\n",
        "\n",
        "            if match.empty:\n",
        "                print(f\"‚ö†Ô∏è Chapter {chapter_str} not found for year {year_str}\")\n",
        "                continue\n",
        "\n",
        "            file_id = match.iloc[0][\"file_id\"]\n",
        "            file_name = match.iloc[0][\"file_name\"]\n",
        "            local_path = os.path.join(download_dir, year_str, f\"{chapter_str}_{file_name}\")\n",
        "\n",
        "            # Ensure folder exists\n",
        "            os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
        "\n",
        "            # Download file\n",
        "            request = drive_service.files().get_media(fileId=file_id)\n",
        "            fh = io.FileIO(local_path, \"wb\")\n",
        "            downloader = MediaIoBaseDownload(fh, request)\n",
        "\n",
        "            done = False\n",
        "            while not done:\n",
        "                status, done = downloader.next_chunk()\n",
        "                if status:\n",
        "                    print(f\"‚¨áÔ∏è Download {int(status.progress() * 100)}% for {file_name}\")\n",
        "\n",
        "            print(f\"‚úÖ Saved {file_name} to {local_path}\")\n",
        "            all_paths[year_str][chapter] = local_path\n",
        "\n",
        "    return all_paths\n",
        "download_all_chapters()"
      ],
      "metadata": {
        "id": "C55Z8A4hs9it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "import subprocess\n",
        "\n",
        "def convert_doc_to_docx(base_dir=\"/content/reports\"):\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        for fname in files:\n",
        "            if fname.endswith(\".doc\") and not fname.endswith(\".docx\"):\n",
        "                fpath = os.path.join(root, fname)\n",
        "                print(fpath)\n",
        "                subprocess.run([\n",
        "                    \"libreoffice\", \"--headless\", \"--convert-to\", \"docx\", fpath, \"--outdir\", root\n",
        "                ])\n",
        "\n",
        "# convert all docs\n",
        "convert_doc_to_docx(\"/content/reports\")"
      ],
      "metadata": {
        "id": "rJss77wStCsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "# Save converted files to google drive\n",
        "def get_original_drive_folder_id(local_file_path, df_files):\n",
        "    \"\"\"\n",
        "    Find the original Drive folder ID for a local file path.\n",
        "\n",
        "    Args:\n",
        "        local_file_path (str): Local path like \"/content/reports/2015/01_chapter01.docx\"\n",
        "        df_files (DataFrame): The existing df_files DataFrame with file metadata\n",
        "\n",
        "    Returns:\n",
        "        str: Drive folder ID of the original year folder, or None if not found\n",
        "    \"\"\"\n",
        "    # Extract the year from the local path\n",
        "    path_parts = local_file_path.replace(\"/content/reports/\", \"\").split(\"/\")\n",
        "\n",
        "    if len(path_parts) < 2:\n",
        "        print(f\"‚ö†Ô∏è Invalid path structure: {local_file_path}\")\n",
        "        return None\n",
        "\n",
        "    year = path_parts[0]\n",
        "\n",
        "    # Find the year folder ID by looking for any file in that year's folder\n",
        "    # and getting its parent folder ID\n",
        "    year_files = df_files[df_files[\"file_path\"].str.startswith(f\"{year}/\")]\n",
        "\n",
        "    if year_files.empty:\n",
        "        print(f\"‚ö†Ô∏è No files found for year: {year}\")\n",
        "        return None\n",
        "\n",
        "    # Get any file from that year to find the parent folder ID\n",
        "    sample_file_id = year_files.iloc[0][\"file_id\"]\n",
        "\n",
        "    try:\n",
        "        # Get file metadata to find its parent folder (which is the year folder)\n",
        "        file_metadata = drive_service.files().get(fileId=sample_file_id, fields='parents').execute()\n",
        "        year_folder_id = file_metadata.get('parents', [None])[0]\n",
        "        return year_folder_id\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error getting year folder for {local_file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def upload_file_to_drive(local_file_path, target_folder_id):\n",
        "    \"\"\"\n",
        "    Upload a single file to a specified Google Drive folder.\n",
        "\n",
        "    Args:\n",
        "        local_file_path (str): Path to the local file to upload\n",
        "        target_folder_id (str): Drive folder ID where the file should be uploaded\n",
        "\n",
        "    Returns:\n",
        "        bool: True if upload successful, False otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract filename from local path\n",
        "        filename = os.path.basename(local_file_path)\n",
        "\n",
        "        # Fix duplicate chapter numbers (e.g., \"09_09.docx\" -> \"09.docx\")\n",
        "        if \"_\" in filename and filename.endswith(\".docx\"):\n",
        "            parts = filename.replace(\".docx\", \"\").split(\"_\")\n",
        "            if len(parts) == 2 and parts[0] == parts[1]:\n",
        "                # If the parts before and after underscore are the same, use just one\n",
        "                filename = f\"{parts[0]}.docx\"\n",
        "\n",
        "        # Set up file metadata\n",
        "        file_metadata = {\n",
        "            'name': filename,\n",
        "            'parents': [target_folder_id]\n",
        "        }\n",
        "\n",
        "        # Create media upload object\n",
        "        media = MediaFileUpload(\n",
        "            local_file_path,\n",
        "            mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document'\n",
        "        )\n",
        "\n",
        "        # Upload the file\n",
        "        uploaded_file = drive_service.files().create(\n",
        "            body=file_metadata,\n",
        "            media_body=media,\n",
        "            fields='id'\n",
        "        ).execute()\n",
        "\n",
        "        file_id = uploaded_file.get('id')\n",
        "        print(f\"‚úÖ Successfully uploaded {filename} (ID: {file_id})\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to upload {local_file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "def upload_converted_files_to_drive(base_dir=\"/content/reports\"):\n",
        "    \"\"\"\n",
        "    Main function to upload all converted .docx files back to their original Google Drive folders\n",
        "    in 'converted' subfolders.\n",
        "\n",
        "    Args:\n",
        "        base_dir (str): Base directory containing the converted files\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Starting upload of converted files to Google Drive...\")\n",
        "\n",
        "    total_files = 0\n",
        "    successful_uploads = 0\n",
        "    failed_uploads = 0\n",
        "\n",
        "    # Walk through the directory structure\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for filename in files:\n",
        "            # Only process .docx files\n",
        "            if filename.endswith(\".docx\"):\n",
        "                total_files += 1\n",
        "                local_file_path = os.path.join(root, filename)\n",
        "\n",
        "                print(f\"\\nüìÅ Processing: {local_file_path}\")\n",
        "\n",
        "                # Step 1: Get the original Drive folder ID\n",
        "                original_folder_id = get_original_drive_folder_id(local_file_path, df_files)\n",
        "                if not original_folder_id:\n",
        "                    print(f\"‚ùå Upload failed for {filename}: Could not find original Drive folder\")\n",
        "                    failed_uploads += 1\n",
        "                    continue\n",
        "\n",
        "                # Step 2: Upload the file\n",
        "                upload_success = upload_file_to_drive(local_file_path, original_folder_id)\n",
        "                if upload_success:\n",
        "                    successful_uploads += 1\n",
        "                else:\n",
        "                    print(f\"‚ùå Upload failed for {filename}: File upload unsuccessful\")\n",
        "                    failed_uploads += 1\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\nüìä Upload Summary:\")\n",
        "    print(f\"   Total .docx files processed: {total_files}\")\n",
        "    print(f\"   Successful uploads: {successful_uploads}\")\n",
        "    print(f\"   Failed uploads: {failed_uploads}\")\n",
        "    print(\"üéâ Upload process completed!\")\n",
        "\n",
        "# Upload all converted files to drive\n",
        "upload_converted_files_to_drive()"
      ],
      "metadata": {
        "id": "CdkNl-Y2tD-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}