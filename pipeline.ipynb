{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiragelb/NCC-Statistical-Reports/blob/main/pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n",
        "!pip install camelot-py[cv]\n",
        "!pip install tabula-py\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Md13rOWPyd0",
        "outputId": "c00838d2-4397-422a-c5a2-9ba9cbbd0ac7"
      },
      "id": "9Md13rOWPyd0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m482.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n",
            "Collecting camelot-py[cv]\n",
            "  Downloading camelot_py-1.0.9-py3-none-any.whl.metadata (9.8 kB)\n",
            "\u001b[33mWARNING: camelot-py 1.0.9 does not provide the extra 'cv'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (8.2.1)\n",
            "Requirement already satisfied: chardet>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (5.2.0)\n",
            "Requirement already satisfied: numpy>=1.26.1 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (2.0.2)\n",
            "Requirement already satisfied: openpyxl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (3.1.5)\n",
            "Requirement already satisfied: pdfminer-six>=20240706 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (20250506)\n",
            "Collecting pypdf<6.0,>=4.0 (from camelot-py[cv])\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pandas>=2.2.2 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (2.2.2)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (0.9.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.7.0.68 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (4.12.0.88)\n",
            "Requirement already satisfied: pypdfium2>=4 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (4.30.0)\n",
            "Requirement already satisfied: pillow>=10.4.0 in /usr/local/lib/python3.12/dist-packages (from camelot-py[cv]) (11.3.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl>=3.1.0->camelot-py[cv]) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.2->camelot-py[cv]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20240706->camelot-py[cv]) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20240706->camelot-py[cv]) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.2->camelot-py[cv]) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py[cv]) (2.22)\n",
            "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading camelot_py-1.0.9-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf, camelot-py\n",
            "Successfully installed camelot-py-1.0.9 pypdf-5.9.0\n",
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.10.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.12/dist-packages (from tabula-py) (2.2.2)\n",
            "Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.12/dist-packages (from tabula-py) (2.0.2)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.12/dist-packages (from tabula-py) (1.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.17.0)\n",
            "Downloading tabula_py-2.10.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tabula-py\n",
            "Successfully installed tabula-py-2.10.0\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "6QwA0xOvTSZ3"
      },
      "id": "6QwA0xOvTSZ3"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from docx import Document\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import camelot\n",
        "import tabula\n",
        "import pdfplumber\n",
        "from docx.shared import Inches # Import Inches for setting image size\n",
        "import json"
      ],
      "metadata": {
        "id": "7lAXSHIxTVA7"
      },
      "id": "7lAXSHIxTVA7",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Tables"
      ],
      "metadata": {
        "id": "u4nJO-WJTYgD"
      },
      "id": "u4nJO-WJTYgD"
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_directory():\n",
        "    \"\"\"Create tables directory if it doesn't exist\"\"\"\n",
        "    if not os.path.exists('tables'):\n",
        "        os.makedirs('tables')\n",
        "        print(\"Created 'tables/' directory\")\n",
        "    else:\n",
        "        print(\"'tables/' directory already exists\")\n",
        "\n",
        "def extract_tables_with_names(docx_path):\n",
        "    \"\"\"Extract tables with their names from DOCX\"\"\"\n",
        "    doc = Document(docx_path)\n",
        "    tables = []\n",
        "\n",
        "    for i, table in enumerate(doc.tables):\n",
        "        # Extract table data\n",
        "        data = []\n",
        "        for row in table.rows:\n",
        "            data.append([cell.text.strip() for cell in row.cells])\n",
        "\n",
        "        if data:\n",
        "            df = pd.DataFrame(data)\n",
        "\n",
        "            # Try to find table name from first row or use default\n",
        "            # Assuming first row might contain the table name\n",
        "            table_name = f\"Table_{i+1}\"  # Default name\n",
        "            if len(data[0]) > 0 and len(data) >= 1:  # Single cell in first row might be title\n",
        "                table_name = data[0][0] if data[0][0] else table_name\n",
        "                df = pd.DataFrame(data[1:])  # Skip title row\n",
        "\n",
        "            tables.append((table_name, df))\n",
        "\n",
        "    return tables\n",
        "\n",
        "def save_tables_to_csv(tables, chapter, year):\n",
        "    \"\"\"Save tables to CSV files and return reference dictionary\"\"\"\n",
        "    reference_dict = {}\n",
        "\n",
        "    for i, (name, df) in enumerate(tables, 1):\n",
        "        # Create filename: table{i}{j}{k}.csv\n",
        "        filename = f\"table{i}{chapter}{year}.csv\"\n",
        "        filepath = os.path.join('tables', filename)\n",
        "\n",
        "        # Save dataframe to CSV\n",
        "        df.to_csv(filepath, index=False, header=False)\n",
        "\n",
        "        # Add to reference dictionary\n",
        "        reference_dict[name] = filepath\n",
        "        print(f\"Saved: {filepath}\")\n",
        "\n",
        "    return reference_dict\n",
        "\n",
        "def save_dictionary_to_json(reference_dict, filename='table_references.json'):\n",
        "    \"\"\"Save reference dictionary to JSON file with proper Unicode support\"\"\"\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(reference_dict, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"Reference dictionary saved to {filename}\")\n",
        "\n",
        "def process_documents(doc1_path, chapter1, year1, doc2_path, chapter2, year2):\n",
        "    \"\"\"Main function to process both documents\"\"\"\n",
        "    # Setup directory\n",
        "    setup_directory()\n",
        "\n",
        "    # Combined dictionary for all tables\n",
        "    all_references = {}\n",
        "\n",
        "    # Process first document\n",
        "    print(f\"\\nProcessing: {doc1_path}\")\n",
        "    tables1 = extract_tables_with_names(doc1_path)\n",
        "    ref_dict1 = save_tables_to_csv(tables1, chapter1, year1)\n",
        "    all_references.update(ref_dict1)\n",
        "\n",
        "    # Process second document\n",
        "    print(f\"\\nProcessing: {doc2_path}\")\n",
        "    tables2 = extract_tables_with_names(doc2_path)\n",
        "    ref_dict2 = save_tables_to_csv(tables2, chapter2, year2)\n",
        "    all_references.update(ref_dict2)\n",
        "\n",
        "    # Save combined dictionary\n",
        "    save_dictionary_to_json(all_references)\n",
        "\n",
        "    print(f\"\\nTotal tables processed: {len(all_references)}\")\n",
        "    return all_references\n",
        "\n",
        "# # Example usage\n",
        "# if _name_ == \"_main_\":\n",
        "#     # Manual input for chapter and year\n",
        "#     references = process_documents(\n",
        "#         'document1.docx', chapter1=1, year1=2024,\n",
        "#         'document2.docx', chapter2=2, year2=2024\n",
        "#     )"
      ],
      "metadata": {
        "id": "TwdQ-81kdkoH"
      },
      "id": "TwdQ-81kdkoH",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload\n",
        "chp1_2001_raw = files.upload()\n",
        "chp1_2002_raw = files.upload()\n",
        "\n",
        "# Extract file names\n",
        "chp1_2001 = list(chp1_2001_raw.keys())[0]\n",
        "chp1_2002 = list(chp1_2002_raw.keys())[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "Q13mkGDjTbLx",
        "outputId": "d2506ae9-b648-4394-cfb2-fd22cd595a9b"
      },
      "id": "Q13mkGDjTbLx",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f31fa3eb-2cf7-48fc-8c02-9e914a78179b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f31fa3eb-2cf7-48fc-8c02-9e914a78179b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving chap 01 (3).docx to chap 01 (3) (5).docx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7832481d-c474-4e0e-8fd4-0ade0415df0c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7832481d-c474-4e0e-8fd4-0ade0415df0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving chap 01 (4).docx to chap 01 (4) (5).docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_documents(chp1_2001, 1, 2001, chp1_2002, 1, 2002)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWqslKxIkIlh",
        "outputId": "917af199-9901-44db-a6b3-8de81bfd0687"
      },
      "id": "UWqslKxIkIlh",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'tables/' directory already exists\n",
            "\n",
            "Processing: chap 01 (3) (5).docx\n",
            "Saved: tables/table112001.csv\n",
            "Saved: tables/table212001.csv\n",
            "Saved: tables/table312001.csv\n",
            "Saved: tables/table412001.csv\n",
            "Saved: tables/table512001.csv\n",
            "Saved: tables/table612001.csv\n",
            "Saved: tables/table712001.csv\n",
            "Saved: tables/table812001.csv\n",
            "Saved: tables/table912001.csv\n",
            "Saved: tables/table1012001.csv\n",
            "Saved: tables/table1112001.csv\n",
            "Saved: tables/table1212001.csv\n",
            "Saved: tables/table1312001.csv\n",
            "Saved: tables/table1412001.csv\n",
            "Saved: tables/table1512001.csv\n",
            "Saved: tables/table1612001.csv\n",
            "Saved: tables/table1712001.csv\n",
            "Saved: tables/table1812001.csv\n",
            "Saved: tables/table1912001.csv\n",
            "Saved: tables/table2012001.csv\n",
            "Saved: tables/table2112001.csv\n",
            "Saved: tables/table2212001.csv\n",
            "Saved: tables/table2312001.csv\n",
            "Saved: tables/table2412001.csv\n",
            "Saved: tables/table2512001.csv\n",
            "\n",
            "Processing: chap 01 (4) (5).docx\n",
            "Saved: tables/table112002.csv\n",
            "Saved: tables/table212002.csv\n",
            "Saved: tables/table312002.csv\n",
            "Saved: tables/table412002.csv\n",
            "Saved: tables/table512002.csv\n",
            "Saved: tables/table612002.csv\n",
            "Saved: tables/table712002.csv\n",
            "Saved: tables/table812002.csv\n",
            "Saved: tables/table912002.csv\n",
            "Saved: tables/table1012002.csv\n",
            "Saved: tables/table1112002.csv\n",
            "Saved: tables/table1212002.csv\n",
            "Saved: tables/table1312002.csv\n",
            "Saved: tables/table1412002.csv\n",
            "Saved: tables/table1512002.csv\n",
            "Saved: tables/table1612002.csv\n",
            "Saved: tables/table1712002.csv\n",
            "Saved: tables/table1812002.csv\n",
            "Saved: tables/table1912002.csv\n",
            "Saved: tables/table2012002.csv\n",
            "Saved: tables/table2112002.csv\n",
            "Saved: tables/table2212002.csv\n",
            "Saved: tables/table2312002.csv\n",
            "Saved: tables/table2412002.csv\n",
            "Saved: tables/table2512002.csv\n",
            "Saved: tables/table2612002.csv\n",
            "Reference dictionary saved to table_references.json\n",
            "\n",
            "Total tables processed: 39\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Table_1': 'tables/table112002.csv',\n",
              " 'ילדים בישראל*\\nלפי דת (אלפים ושיעור גידולם)\\n2001-1970': 'tables/table212001.csv',\n",
              " 'אחוז הילדים בישראל מכלל האוכלוסייה\\nלפי דת \\n2001-1970': 'tables/table312001.csv',\n",
              " 'התפלגות אוכלוסיית הילדים בישראל\\nלפי דת (אחוזים)\\nסוף 2001': 'tables/table412001.csv',\n",
              " 'ילדים בישראל לפי גיל ודת\\n(אלפים)\\nסוף שנת 2001': 'tables/table512001.csv',\n",
              " 'מספר הילדים\\nלפי גיל, דת, סוג וגודל יישוב (אלפים*)\\nממוצע 2001': 'tables/table612001.csv',\n",
              " 'מספר הילדים\\nלפי גיל, דת, סוג וגודל יישוב (אלפים*)\\nממוצע 2001 (המשך)': 'tables/table812001.csv',\n",
              " 'מספר הילדים, חלקם באוכלוסייה ודתם \\nלפי מחוז ונפה (אלפים ואחוזים)\\nממוצע 2001': 'tables/table912001.csv',\n",
              " 'מספר הילדים לפי גיל וחלקם באוכלוסיית היישובים* \\n(אלפים ואחוזים)\\nסוף דצמבר 2001': 'tables/table1012001.csv',\n",
              " 'מספר הילדים לפי גיל וחלקם באוכלוסיית היישובים* \\n(אלפים ואחוזים)\\nסוף דצמבר 2001 (המשך)': 'tables/table1412001.csv',\n",
              " 'חלקם של  הילדים באוכלוסיית היישובים שמנו 10,000 תושבים ויותר \\n(אחוזים)\\nסוף דצמבר 2001': 'tables/table1512001.csv',\n",
              " 'חלקם של  הילדים באוכלוסיית היישובים שמנו 10,000-5,000 תושבים \\n(אחוזים)\\nסוף דצמבר 2001': 'tables/table1612001.csv',\n",
              " 'יישובים נבחרים שבהם  הילדים \\nמונים פחות מ-25% או יותר מ-50% מהאוכלוסייה\\nסוף דצמבר 2001': 'tables/table1712001.csv',\n",
              " 'אחוז  הילדים המתגוררים ביישובים \\nהלא מוכרים בנגב ( מכלל אוכלוסיית היישובים) \\nמאי 2002': 'tables/table1812001.csv',\n",
              " 'גיל הילדים המתגוררים ביישובים \\nהלא מוכרים בנגב (אחוזים)\\nמאי 2002': 'tables/table1912001.csv',\n",
              " 'מוצאם* של ילדים יהודיים בגיל 17-0 \\nלפי גיל (אלפים**)\\nממוצע 2001': 'tables/table2012001.csv',\n",
              " \"תרשים 1ה'\": 'tables/table2112001.csv',\n",
              " 'לידות חי\\nלפי מחוז, נפה וקבוצת אוכלוסייה (מספרים)\\n2001-1995': 'tables/table2212001.csv',\n",
              " 'לידות חי \\n לפי יישוב* (מספרים)\\n2001-1995': 'tables/table2312001.csv',\n",
              " 'לידות חי \\nלפי יישוב* \\n(מספרים מוחלטים) 2001-1995 (המשך)': 'tables/table2512001.csv',\n",
              " 'ילדים בישראל*\\nלפי דת (אלפים ושיעור גידולם)\\n2000-1970': 'tables/table212002.csv',\n",
              " 'אחוז הילדים בישראל מכלל האוכלוסייה\\nלפי דת \\n2000-1970': 'tables/table312002.csv',\n",
              " 'מספר הילדים\\nלפי גיל, דת, סוג וגודל יישוב (אלפים*)\\nממוצע 2000': 'tables/table412002.csv',\n",
              " 'מספר הילדים\\nלפי גיל, דת, סוג וגודל יישוב (אלפים*)\\nממוצע 2000 (המשך)': 'tables/table512002.csv',\n",
              " 'מספר הילדים, חלקם באוכלוסייה ודתם \\nלפי מחוז ונפה (אלפים ואחוזים)\\nממוצע 2000': 'tables/table612002.csv',\n",
              " 'מספר הילדים ביישובים מעורבים נבחרים \\nלפי דת (אלפים ואחוזים)\\nסוף דצמבר 2000': 'tables/table712002.csv',\n",
              " 'מספר הילדים לפי גיל וחלקם באוכלוסיית היישובים* \\n(אלפים ואחוזים)\\nסוף דצמבר 2000': 'tables/table812002.csv',\n",
              " 'מספר הילדים לפי גיל וחלקם באוכלוסיית היישובים* \\n(אלפים ואחוזים)\\nסוף דצמבר 2000 (המשך)': 'tables/table1212002.csv',\n",
              " 'חלקם של  הילדים באוכלוסיית היישובים שמנו 10,000 תושבים ויותר \\n(אחוזים)\\nסוף דצמבר 2000': 'tables/table1312002.csv',\n",
              " 'חלקם של  הילדים באוכלוסיית היישובים שמנו 10,000-5,000 תושבים \\n(אחוזים)\\nסוף דצמבר 2000': 'tables/table1412002.csv',\n",
              " 'אחוז  הילדים מכלל האוכלוסייה \\nביישובים נבחרים שבהם  הם מונים פחות מ-25% או יותר מ-50% \\nסוף דצמבר 2000': 'tables/table1512002.csv',\n",
              " 'ילדים בישראל לפי גיל ודת\\n(אלפים)\\nסוף שנת 2000': 'tables/table1612002.csv',\n",
              " \"תרשים 1ב'\": 'tables/table1712002.csv',\n",
              " 'ילדים אשר על פי מרשם האוכלוסין אינם קשורים להורה/הורים \\nלפי יישוב מגורים* \\n(מספרים ושיעורים ל-1,000) מרץ 2001': 'tables/table1812002.csv',\n",
              " 'ילדים אשר על פי מרשם האוכלוסין אינם קשורים להורה/הורים \\nלפי יישוב מגורים* \\n(מספרים ושיעורים ל-1,000) מרץ 2001 (המשך)': 'tables/table2212002.csv',\n",
              " 'מוצאם* של ילדים יהודיים בגיל 17-0 \\nלפי גיל (אלפים**)\\nממוצע 2000': 'tables/table2312002.csv',\n",
              " 'לידות חי\\nלפי מחוז, נפה וקבוצת אוכלוסייה (מספרים מוחלטים)\\n2000-1995': 'tables/table2412002.csv',\n",
              " 'לידות חי \\n לפי יישוב* (מספרים)\\n2000-1995': 'tables/table2512002.csv',\n",
              " 'לידות חי \\nלפי יישוב* \\n(מספרים מוחלטים) 2000-1995 (המשך)': 'tables/table2612002.csv'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previous"
      ],
      "metadata": {
        "id": "ytB93qaLVEhC"
      },
      "id": "ytB93qaLVEhC"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def process_file_from_url(url, year):\n",
        "    \"\"\"\n",
        "    Downloads a file from a URL, processes it, extracts tables from DOCX,\n",
        "    saves them as CSVs, and stores metadata.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the file.\n",
        "        year (int): The year to include in the CSV filenames.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping original table topics to their new filenames.\n",
        "    \"\"\"\n",
        "    # Step 2: Download the file\n",
        "    local_filename = url.split('/')[-1]\n",
        "    print(f\"Downloading {url} to {local_filename}\")\n",
        "    try:\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(local_filename, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "        print(\"Download complete.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading file: {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "    # Step 3: Determine file type and convert if necessary\n",
        "    file_extension = os.path.splitext(local_filename)[1].lower()\n",
        "    docx_path = local_filename\n",
        "\n",
        "    if file_extension == '.pdf':\n",
        "        print(f\"Detected PDF file. Attempting to convert {local_filename} to DOCX.\")\n",
        "        try:\n",
        "            # Basic PDF to DOCX conversion using pdfplumber\n",
        "            # This will extract text but may not preserve formatting or tables accurately.\n",
        "            # For better results, consider using libraries like 'pdf2docx' or external services.\n",
        "            docx_path = local_filename + \".docx\"\n",
        "            document = Document()\n",
        "            with pdfplumber.open(local_filename) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    text = page.extract_text()\n",
        "                    if text:\n",
        "                        document.add_paragraph(text)\n",
        "            document.save(docx_path)\n",
        "            print(f\"Conversion to DOCX complete: {docx_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting PDF to DOCX: {e}\")\n",
        "            print(\"Proceeding with the original file assuming it might be parsable by a DOCX reader or skipping table extraction.\")\n",
        "            # If conversion fails, we might not be able to extract tables reliably.\n",
        "            # Depending on requirements, you might want to return here or handle this case differently.\n",
        "\n",
        "\n",
        "    elif file_extension == '.docx':\n",
        "        print(f\"Detected DOCX file: {local_filename}\")\n",
        "        pass # File is already DOCX, no conversion needed\n",
        "    else:\n",
        "        print(f\"Unsupported file type: {file_extension}. Skipping table extraction.\")\n",
        "        return {} # Return empty dictionary for unsupported types\n",
        "\n",
        "\n",
        "    # Step 4: Extract tables from DOCX\n",
        "    tables = []\n",
        "    if os.path.exists(docx_path):\n",
        "      try:\n",
        "          tables = extract_tables_from_docx(docx_path)\n",
        "          print(f\"Extracted {len(tables)} tables from {docx_path}\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error extracting tables from DOCX: {e}\")\n",
        "          return {}\n",
        "    else:\n",
        "      print(f\"DOCX file not found at {docx_path}. Skipping table extraction.\")\n",
        "      return {}\n",
        "\n",
        "\n",
        "    # Step 5: Save tables as CSV and store metadata\n",
        "    table_metadata = {}\n",
        "    for i, table in enumerate(tables, 1):\n",
        "        # Placeholder for extracting original table topic\n",
        "        # This is highly dependent on the document structure and might require\n",
        "        # more advanced parsing or heuristics.\n",
        "        original_topic = f\"Table {i}\" # Using a placeholder for now\n",
        "\n",
        "        csv_filename = f\"{i}-{year}.csv\"\n",
        "        table.to_csv(csv_filename, index=False)\n",
        "        table_metadata[original_topic] = csv_filename\n",
        "        print(f\"Saved table {i} to {csv_filename}\")\n",
        "\n",
        "    # Step 6: Return the dictionary\n",
        "    return table_metadata\n",
        "\n",
        "def extract_tables_from_docx(docx_path):\n",
        "    \"\"\"\n",
        "    Extracts tables from a DOCX file.\n",
        "\n",
        "    Args:\n",
        "        docx_path (str): The path to the DOCX file.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of pandas DataFrames, where each DataFrame represents a table.\n",
        "    \"\"\"\n",
        "    doc = Document(docx_path)\n",
        "    tables = []\n",
        "\n",
        "    for table in doc.tables:\n",
        "        data = []\n",
        "        for row in table.rows:\n",
        "            data.append([cell.text.strip() for cell in row.cells])\n",
        "        if data: # Ensure table is not empty\n",
        "            df = pd.DataFrame(data)\n",
        "            tables.append(df)\n",
        "    return tables\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.chdir('content/drive/Shareddrives/')\n",
        "\n",
        "# Example usage (You can uncomment and modify this to test)\n",
        "url = pdf_path # Replace with the actual file URL\n",
        "year = 2024 # Replace with the desired year\n",
        "extracted_info = process_file_from_url(url, year)\n",
        "print(\"\\nExtracted Information:\")\n",
        "print(extracted_info)"
      ],
      "metadata": {
        "id": "1Q5nm6WiPzlr"
      },
      "id": "1Q5nm6WiPzlr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}